
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>feature_extraction.FeatureHasher() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Implements feature hashing, aka the hashing trick. ">
  <meta name="keywords" content="sklearn, feature, extraction, featurehasher, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.feature_extraction.featurehasher/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-e0f881b0fce8cbe96f33dadc355b7159d5d2912911231446d60eb8f9caffa802.css">
  <script type="text/javascript" src="/assets/application-8fc46316434047265cd383f02b8e7f434ed7dec4a59f920dd633deef8d488d1b.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-feature-extraction-featurehasher">sklearn.feature_extraction.FeatureHasher</h1> <dl class="class"> <dt id="sklearn.feature_extraction.FeatureHasher">
<code>class sklearn.feature_extraction.FeatureHasher(n_features=1048576, input_type=’dict’, dtype=&lt;class ‘numpy.float64’&gt;, alternate_sign=True, non_negative=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/feature_extraction/hashing.py#L19" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Implements feature hashing, aka the hashing trick.</p> <p>This class turns sequences of symbolic feature names (strings) into scipy.sparse matrices, using a hash function to compute the matrix column corresponding to a name. The hash function employed is the signed 32-bit version of Murmurhash3.</p> <p>Feature names of type byte string are used as-is. Unicode strings are converted to UTF-8 first, but no Unicode normalization is done. Feature values must be (finite) numbers.</p> <p>This class is a low-memory alternative to DictVectorizer and CountVectorizer, intended for large-scale (online) learning and situations where memory is tight, e.g. when running prediction code on embedded devices.</p> <p>Read more in the <a class="reference internal" href="../../feature_extraction/#feature-hashing"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>n_features</strong> : integer, optional</p>  <p>The number of features (columns) in the output matrices. Small numbers of features are likely to cause hash collisions, but large numbers will cause larger coefficient dimensions in linear learners.</p>  <p><strong>input_type</strong> : string, optional, default “dict”</p>  <p>Either “dict” (the default) to accept dictionaries over (feature_name, value); “pair” to accept pairs of (feature_name, value); or “string” to accept single strings. feature_name should be a string, while value should be a number. In the case of “string”, a value of 1 is implied. The feature_name is hashed to find the appropriate column for the feature. The value’s sign might be flipped in the output (but see non_negative, below).</p>  <p><strong>dtype</strong> : numpy type, optional, default np.float64</p>  <p>The type of feature values. Passed to scipy.sparse matrix constructors as the dtype argument. Do not set this to bool, np.boolean or any unsigned integer type.</p>  <p><strong>alternate_sign</strong> : boolean, optional, default True</p>  <p>When True, an alternating sign is added to the features as to approximately conserve the inner product in the hashed space even for small n_features. This approach is similar to sparse random projection.</p>  <p><strong>non_negative</strong> : boolean, optional, default False</p>  <p>When True, an absolute value is applied to the features matrix prior to returning it. When used in conjunction with alternate_sign=True, this significantly reduces the inner product preservation property.</p> <div class="deprecated"> <p><span class="versionmodified">Deprecated since version 0.19: </span>This option will be removed in 0.21.</p> </div>  </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <dl class="last docutils"> <dt>
 <a class="reference internal" href="../sklearn.feature_extraction.dictvectorizer/#sklearn.feature_extraction.DictVectorizer" title="sklearn.feature_extraction.DictVectorizer"><code>DictVectorizer</code></a>
</dt> <dd>vectorizes string-valued features using a hash table.</dd> <dt>
 <a class="reference internal" href="../sklearn.preprocessing.onehotencoder/#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code>sklearn.preprocessing.OneHotEncoder</code></a>
</dt> <dd>handles nominal/categorical features encoded as columns of integers.</dd> </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.feature_extraction import FeatureHasher
&gt;&gt;&gt; h = FeatureHasher(n_features=10)
&gt;&gt;&gt; D = [{'dog': 1, 'cat':2, 'elephant':4},{'dog': 2, 'run': 5}]
&gt;&gt;&gt; f = h.transform(D)
&gt;&gt;&gt; f.toarray()
array([[ 0.,  0., -4., -1.,  0.,  0.,  0.,  0.,  0.,  2.],
       [ 0.,  0.,  0., -2., -5.,  0.,  0.,  0.,  0.,  0.]])
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr>
<td>
<a class="reference internal" href="#sklearn.feature_extraction.FeatureHasher.fit" title="sklearn.feature_extraction.FeatureHasher.fit"><code>fit</code></a>([X, y])</td> <td>No-op.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.feature_extraction.FeatureHasher.fit_transform" title="sklearn.feature_extraction.FeatureHasher.fit_transform"><code>fit_transform</code></a>(X[, y])</td> <td>Fit to data, then transform it.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.feature_extraction.FeatureHasher.get_params" title="sklearn.feature_extraction.FeatureHasher.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.feature_extraction.FeatureHasher.set_params" title="sklearn.feature_extraction.FeatureHasher.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.feature_extraction.FeatureHasher.transform" title="sklearn.feature_extraction.FeatureHasher.transform"><code>transform</code></a>(raw_X)</td> <td>Transform a sequence of instances to a scipy.sparse matrix.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.feature_extraction.FeatureHasher.__init__">
<code>__init__(n_features=1048576, input_type=’dict’, dtype=&lt;class ‘numpy.float64’&gt;, alternate_sign=True, non_negative=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/feature_extraction/hashing.py#L88" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.feature_extraction.FeatureHasher.fit">
<code>fit(X=None, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/feature_extraction/hashing.py#L116" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>No-op.</p> <p>This method doesn’t do anything. It exists purely for compatibility with the scikit-learn transformer API.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<strong>X</strong> : array-like</td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> : FeatureHasher</td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.feature_extraction.FeatureHasher.fit_transform">
<code>fit_transform(X, y=None, **fit_params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/base.py#L493" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit to data, then transform it.</p> <p>Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : numpy array of shape [n_samples, n_features]</p>  <p>Training set.</p>  <p><strong>y</strong> : numpy array of shape [n_samples]</p>  <p>Target values.</p>  </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>X_new</strong> : numpy array of shape [n_samples, n_features_new]</p>  <p>Transformed array.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.feature_extraction.FeatureHasher.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/base.py#L213" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep</strong> : boolean, optional</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.feature_extraction.FeatureHasher.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/base.py#L250" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.feature_extraction.FeatureHasher.transform">
<code>transform(raw_X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/feature_extraction/hashing.py#L135" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Transform a sequence of instances to a scipy.sparse matrix.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>raw_X</strong> : iterable over iterable over raw features, length = n_samples</p>  <p>Samples. Each sample must be iterable an (e.g., a list or tuple) containing/generating feature names (and optionally values, see the input_type constructor argument) which will be hashed. raw_X need not support the len function, so it can be the result of a generator; n_samples is determined on the fly.</p>  </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : scipy.sparse matrix, shape = (n_samples, self.n_features)</p>  <p>Feature matrix, for use with estimators or further transformers.</p>  </td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-feature-extraction-featurehasher">Examples using <code>sklearn.feature_extraction.FeatureHasher</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="Compares FeatureHasher and DictVectorizer by using both to vectorize text documents.">
<div class="figure" id="id1"> <img alt="../../_images/sphx_glr_hashing_vs_dict_vectorizer_thumb.png" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAACMBAMAAADLv/vXAAAAG1BMVEX+5r665vT///+55vT+5rz+/v3+9ufv+fzV8Pdywf0dAAADeUlEQVRo3u3azW6cMBAHcCviBRAv0AaQeoVRlB6t1aQPQBL1XqUv0L6/VLzLbrCZ8cesWUWpLSWH3cNPHgzM/BN1f4OlClKQghSkIMlIC/Nq4A/zdY+oEfHuKuQZlvWdJN5moJp/8OkKpIWhPq4GgPh63oY6rgoPYuRi1DUQyrwDpaIVDnk3DDM633YXwiwUIi2sjLlio2PoNVIdZIi1EaPYxVL2QhHybG3EKA+rb1+0g4S2QiPt4CKrgjnFEiPuRqyCbYxgvUik3yI1PJAna0GmdGRTLbOVkbsi4XrFI+d6EYYIIap1uSOpaoUuSjyy1KvTeyI1kDfiLojeGRnZS5IPOV6UbuedHJ9fLzsjx4tCV+s2SJUV0epTlGvkTrAA6RlkPsNdvnL9TUZ+5HnULwhzuO4ECCTuBA8fFOEfXp3kXoxvJE7IF8nhiu27/OXK1NztgbBveckbnkP65yEBqZ5ECF0vFhGODu7scHpATvM0ShjSIYjcCvM+CW6ERb5B9PsEf4mnX6JeHPIqRojz9Th//CaolicsAKD6rs1zBQOziR95dQtGd5ARRiBbIQYUe5jTEXmEPyWylOYyn+h1rWIMfxRlcqLhHH3Ae6qCy00YaYTyrhlZsqL1iG2SFZMR6Vyh2imRmtyoKy6DikX63vxyPpzuk9b/FHT2b/h78+HP4XHKhphLXGlzWK0jt6wpC1Kdo8bVLWFunnM4Gcko7zaq6vKsPUeNLVjp5HQtgkj0JPZjc4ArEcc4vTjcNhngKmTzUD8hA53rCBFUUUgNVyAdHQIOfNomQJDsRnvggh0JQrWKSDfJ4a1wCGp61IHaF7SmIeS8Pt+O5KAXPGAqvlrmeLWe4DAZQQb5Snb7IEJekBmo6BEsVC8VXy0eaSRIj4kISHZCZ0EsUsN0C0Swky4ZGQWITkQaCaISkVqAYDIC2RB1C2QeqnrIhmg+1dodwawIfnKEaYnyIsdmuG32vfAY/HvXx0PQk2bSF2W4BQKZHvXoCVqbMTcyZELQkzSS6eSY5R3/Hpn2THCYjmhPCLjth2Ut0aaDtLJfGLJ0kNv/TDn4/oYj64Xd82UnW72TgUq7evuqIPqSVvEQZG2FCOPXSnjI5gdTrZ3Aw0knvf/+FT3H4zm6ofr++yXGiTH8sYdZGtkM9LRKPFiQghSkIAUpSEEK8n8h/wBTQzVtmPrLuAAAAABJRU5ErkJggg=="> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/text/hashing_vs_dict_vectorizer/#sphx-glr-auto-examples-text-hashing-vs-dict-vectorizer-py"><span class="std std-ref">FeatureHasher and DictVectorizer Comparison</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2017 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
