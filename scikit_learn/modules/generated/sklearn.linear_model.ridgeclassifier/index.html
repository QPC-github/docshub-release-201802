
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>linear_model.RidgeClassifier() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Classifier using Ridge regression. ">
  <meta name="keywords" content="sklearn, linear, model, ridgeclassifier, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.linear_model.ridgeclassifier/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-e0f881b0fce8cbe96f33dadc355b7159d5d2912911231446d60eb8f9caffa802.css">
  <script type="text/javascript" src="/assets/application-8fc46316434047265cd383f02b8e7f434ed7dec4a59f920dd633deef8d488d1b.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-linear-model-ridgeclassifier">sklearn.linear_model.RidgeClassifier</h1> <dl class="class"> <dt id="sklearn.linear_model.RidgeClassifier">
<code>class sklearn.linear_model.RidgeClassifier(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, class_weight=None, solver=’auto’, random_state=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/linear_model/ridge.py#L668" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Classifier using Ridge regression.</p> <p>Read more in the <a class="reference internal" href="../../linear_model/#ridge-regression"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>alpha</strong> : float</p>  <p>Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to <code>C^-1</code> in other linear models such as LogisticRegression or LinearSVC.</p>  <p><strong>fit_intercept</strong> : boolean</p>  <p>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).</p>  <p><strong>normalize</strong> : boolean, optional, default False</p>  <p>This parameter is ignored when <code>fit_intercept</code> is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use <a class="reference internal" href="../sklearn.preprocessing.standardscaler/#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>sklearn.preprocessing.StandardScaler</code></a> before calling <code>fit</code> on an estimator with <code>normalize=False</code>.</p>  <p><strong>copy_X</strong> : boolean, optional, default True</p>  <p>If True, X will be copied; else, it may be overwritten.</p>  <p><strong>max_iter</strong> : int, optional</p>  <p>Maximum number of iterations for conjugate gradient solver. The default value is determined by scipy.sparse.linalg.</p>  <p><strong>tol</strong> : float</p>  <p>Precision of the solution.</p>  <p><strong>class_weight</strong> : dict or ‘balanced’, optional</p>  <p>Weights associated with classes in the form <code>{class_label: weight}</code>. If not given, all classes are supposed to have weight one.</p> <p>The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as <code>n_samples / (n_classes * np.bincount(y))</code></p>  <p><strong>solver</strong> : {‘auto’, ‘svd’, ‘cholesky’, ‘lsqr’, ‘sparse_cg’, ‘sag’, ‘saga’}</p>  <p>Solver to use in the computational routines:</p> <ul> <li>‘auto’ chooses the solver automatically based on the type of data. </li> <li>‘svd’ uses a Singular Value Decomposition of X to compute the Ridge coefficients. More stable for singular matrices than ‘cholesky’. </li> <li>‘cholesky’ uses the standard scipy.linalg.solve function to obtain a closed-form solution. </li> <li>‘sparse_cg’ uses the conjugate gradient solver as found in scipy.sparse.linalg.cg. As an iterative algorithm, this solver is more appropriate than ‘cholesky’ for large-scale data (possibility to set <code>tol</code> and <code>max_iter</code>). </li> <li>‘lsqr’ uses the dedicated regularized least-squares routine scipy.sparse.linalg.lsqr. It is the fastest but may not be available in old scipy versions. It also uses an iterative procedure. </li> <li>
<p class="first">‘sag’ uses a Stochastic Average Gradient descent, and ‘saga’ uses its unbiased and more flexible version named SAGA. Both methods use an iterative procedure, and are often faster than other solvers when both n_samples and n_features are large. Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17: </span>Stochastic Average Gradient descent solver.</p> </div> <div class="versionadded"> <p><span class="versionmodified">New in version 0.19: </span>SAGA solver.</p> </div> </li> </ul>  <p><strong>random_state</strong> : int, RandomState instance or None, optional, default None</p>  <p>The seed of the pseudo random number generator to use when shuffling the data. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by <code>np.random</code>. Used when <code>solver</code> == ‘sag’.</p>  </td> </tr> <tr>
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>coef_</strong> : array, shape (n_features,) or (n_classes, n_features)</p>  <p>Weight vector(s).</p>  <p><strong>intercept_</strong> : float | array, shape = (n_targets,)</p>  <p>Independent term in decision function. Set to 0.0 if <code>fit_intercept = False</code>.</p>  <p><strong>n_iter_</strong> : array or None, shape (n_targets,)</p>  <p>Actual number of iterations for each target. Available only for sag and lsqr solvers. Other solvers will return None.</p>  </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><a class="reference internal" href="../sklearn.linear_model.ridge/#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code>Ridge</code></a>, <a class="reference internal" href="../sklearn.linear_model.ridgeclassifiercv/#sklearn.linear_model.RidgeClassifierCV" title="sklearn.linear_model.RidgeClassifierCV"><code>RidgeClassifierCV</code></a></p> </div> <h4 class="rubric">Notes</h4> <p>For multi-class classification, n_class classifiers are trained in a one-versus-all approach. Concretely, this is implemented by taking advantage of the multi-variate response support in Ridge.</p> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.decision_function" title="sklearn.linear_model.RidgeClassifier.decision_function"><code>decision_function</code></a>(X)</td> <td>Predict confidence scores for samples.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.fit" title="sklearn.linear_model.RidgeClassifier.fit"><code>fit</code></a>(X, y[, sample_weight])</td> <td>Fit Ridge regression model.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.get_params" title="sklearn.linear_model.RidgeClassifier.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.predict" title="sklearn.linear_model.RidgeClassifier.predict"><code>predict</code></a>(X)</td> <td>Predict class labels for samples in X.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.score" title="sklearn.linear_model.RidgeClassifier.score"><code>score</code></a>(X, y[, sample_weight])</td> <td>Returns the mean accuracy on the given test data and labels.</td> </tr> <tr>
<td>
<a class="reference internal" href="#sklearn.linear_model.RidgeClassifier.set_params" title="sklearn.linear_model.RidgeClassifier.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.linear_model.RidgeClassifier.__init__">
<code>__init__(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, class_weight=None, solver=’auto’, random_state=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/linear_model/ridge.py#L777" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.linear_model.RidgeClassifier.decision_function">
<code>decision_function(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/linear_model/base.py#L278" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict confidence scores for samples.</p> <p>The confidence score for a sample is the signed distance of that sample to the hyperplane.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = (n_samples, n_features)</p>  <p>Samples.</p>  </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)</strong> :</p>  <p>Confidence scores per (sample, class) combination. In the binary case, confidence score for self.classes_[1] where &gt;0 means this class would be predicted.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.RidgeClassifier.fit">
<code>fit(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/linear_model/ridge.py#L786" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit Ridge regression model.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples,n_features]</p>  <p>Training data</p>  <p><strong>y</strong> : array-like, shape = [n_samples]</p>  <p>Target values</p>  <p><strong>sample_weight</strong> : float or numpy array of shape (n_samples,)</p>  <p>Sample weight.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17: </span><em>sample_weight</em> support to Classifier.</p> </div>  </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first last"><strong>self</strong> : returns an instance of self.</p> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.RidgeClassifier.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/base.py#L213" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep</strong> : boolean, optional</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.RidgeClassifier.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/linear_model/base.py#L311" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class labels for samples in X.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>  <p>Samples.</p>  </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>C</strong> : array, shape = [n_samples]</p>  <p>Predicted class label per sample.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.RidgeClassifier.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/base.py#L324" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the mean accuracy on the given test data and labels.</p> <p>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape = (n_samples, n_features)</p>  <p>Test samples.</p>  <p><strong>y</strong> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>  <p>True labels for X.</p>  <p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>  <p>Sample weights.</p>  </td> </tr> <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>score</strong> : float</p>  <p>Mean accuracy of self.predict(X) wrt. y.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.RidgeClassifier.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f/sklearn/base.py#L250" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-linear-model-ridgeclassifier">Examples using <code>sklearn.linear_model.RidgeClassifier</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how scikit-learn can be used to classify documents by topics using a...">
<div class="figure" id="id1"> <img alt="../../_images/sphx_glr_document_classification_20newsgroups_thumb.png" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAACMBAMAAADLv/vXAAAAG1BMVEX+5r665vT///+55vT+5rz+/v3+9ufv+fzV8Pdywf0dAAADeUlEQVRo3u3azW6cMBAHcCviBRAv0AaQeoVRlB6t1aQPQBL1XqUv0L6/VLzLbrCZ8cesWUWpLSWH3cNPHgzM/BN1f4OlClKQghSkIMlIC/Nq4A/zdY+oEfHuKuQZlvWdJN5moJp/8OkKpIWhPq4GgPh63oY6rgoPYuRi1DUQyrwDpaIVDnk3DDM633YXwiwUIi2sjLlio2PoNVIdZIi1EaPYxVL2QhHybG3EKA+rb1+0g4S2QiPt4CKrgjnFEiPuRqyCbYxgvUik3yI1PJAna0GmdGRTLbOVkbsi4XrFI+d6EYYIIap1uSOpaoUuSjyy1KvTeyI1kDfiLojeGRnZS5IPOV6UbuedHJ9fLzsjx4tCV+s2SJUV0epTlGvkTrAA6RlkPsNdvnL9TUZ+5HnULwhzuO4ECCTuBA8fFOEfXp3kXoxvJE7IF8nhiu27/OXK1NztgbBveckbnkP65yEBqZ5ECF0vFhGODu7scHpATvM0ShjSIYjcCvM+CW6ERb5B9PsEf4mnX6JeHPIqRojz9Th//CaolicsAKD6rs1zBQOziR95dQtGd5ARRiBbIQYUe5jTEXmEPyWylOYyn+h1rWIMfxRlcqLhHH3Ae6qCy00YaYTyrhlZsqL1iG2SFZMR6Vyh2imRmtyoKy6DikX63vxyPpzuk9b/FHT2b/h78+HP4XHKhphLXGlzWK0jt6wpC1Kdo8bVLWFunnM4Gcko7zaq6vKsPUeNLVjp5HQtgkj0JPZjc4ArEcc4vTjcNhngKmTzUD8hA53rCBFUUUgNVyAdHQIOfNomQJDsRnvggh0JQrWKSDfJ4a1wCGp61IHaF7SmIeS8Pt+O5KAXPGAqvlrmeLWe4DAZQQb5Snb7IEJekBmo6BEsVC8VXy0eaSRIj4kISHZCZ0EsUsN0C0Swky4ZGQWITkQaCaISkVqAYDIC2RB1C2QeqnrIhmg+1dodwawIfnKEaYnyIsdmuG32vfAY/HvXx0PQk2bSF2W4BQKZHvXoCVqbMTcyZELQkzSS6eSY5R3/Hpn2THCYjmhPCLjth2Ut0aaDtLJfGLJ0kNv/TDn4/oYj64Xd82UnW72TgUq7evuqIPqSVvEQZG2FCOPXSnjI5gdTrZ3Aw0knvf/+FT3H4zm6ofr++yXGiTH8sYdZGtkM9LRKPFiQghSkIAUpSEEK8n8h/wBTQzVtmPrLuAAAAABJRU5ErkJggg=="> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/text/document_classification_20newsgroups/#sphx-glr-auto-examples-text-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2017 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
