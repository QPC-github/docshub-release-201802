
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>BaseAudioContext - DOM - W3cubDocs</title>
  
  <meta name="description" content="The BaseAudioContext interface acts as a base definition for online and offline audio-processing graphs, as represented by AudioContext and &hellip;">
  <meta name="keywords" content="baseaudiocontext, -, dom">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/dom/baseaudiocontext/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-e0f881b0fce8cbe96f33dadc355b7159d5d2912911231446d60eb8f9caffa802.css">
  <script type="text/javascript" src="/assets/application-8fc46316434047265cd383f02b8e7f434ed7dec4a59f920dd633deef8d488d1b.js"></script>
  <script src="/json/dom.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/dom/" class="_nav-link" title="" style="margin-left:0;">DOM</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _mdn">
				
<h1>BaseAudioContext</h1> <p class="summary">The <code>BaseAudioContext</code> interface acts as a base definition for online and offline audio-processing graphs, as represented by <a href="../audiocontext/"><code>AudioContext</code></a> and <a href="../offlineaudiocontext/"><code>OfflineAudioContext</code></a> respectively. You wouldn't use <code>BaseAudioContext</code> directly â€” you'd use its features via one of these two inheriting interfaces.</p> <p>A <code>BaseAudioContext</code> can be a target of events, therefore it implements the <a href="../eventtarget/"><code>EventTarget</code></a> interface.</p>  <iframe class="live-sample-frame inheritance-diagram-frame" width="600" height="70" id="frame_inheritance_diagram" src="https://mdn.mozillademos.org/en-US/docs/Web/API/BaseAudioContext%24samples/inheritance_diagram?revision=1337935" frameborder="0"></iframe> <h2 id="Properties">Properties</h2> <dl> <dt>
<a href="https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext/audioWorklet" target="_blank"><code>BaseAudioContext.audioWorklet</code></a>  <span class="inlineIndicator readOnly readOnlyInline">Read only </span>
</dt> <dd>Returns the <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioWorklet" target="_blank"><code>AudioWorklet</code></a> object, used for creating custom AudioNodes with JavaScript processing.</dd> <dt>
<a href="../baseaudiocontext/currenttime/"><code>BaseAudioContext.currentTime</code></a> <span class="inlineIndicator readOnly readOnlyInline">Read only </span>
</dt> <dd>Returns a double representing an ever-increasing hardware time in seconds used for scheduling. It starts at <code>0</code>.</dd> <dt>
<a href="../baseaudiocontext/destination/"><code>BaseAudioContext.destination</code></a> <span class="inlineIndicator readOnly readOnlyInline">Read only </span>
</dt> <dd>Returns an <a href="../audiodestinationnode/"><code>AudioDestinationNode</code></a> representing the final destination of all audio in the context. It can be thought of as the audio-rendering device.</dd> <dt>
<a href="../baseaudiocontext/listener/"><code>BaseAudioContext.listener</code></a> <span class="inlineIndicator readOnly readOnlyInline">Read only </span>
</dt> <dd>Returns the <a href="../audiolistener/"><code>AudioListener</code></a> object, used for 3D spatialization.</dd> <dt>
<a href="../baseaudiocontext/samplerate/"><code>BaseAudioContext.sampleRate</code></a> <span class="inlineIndicator readOnly readOnlyInline">Read only </span>
</dt> <dd>Returns a float representing the sample rate (in samples per second) used by all nodes in this context. The sample-rate of an <a href="../audiocontext/"><code>AudioContext</code></a> cannot be changed.</dd> <dt>
<a href="../baseaudiocontext/state/"><code>BaseAudioContext.state</code></a> <span class="inlineIndicator readOnly readOnlyInline">Read only </span>
</dt> <dd>Returns the current state of the <code>AudioContext</code>.</dd> </dl> <h3 id="Event_handlers">Event handlers</h3> <dl> <dt><a href="../baseaudiocontext/onstatechange/"><code>BaseAudioContext.onstatechange</code></a></dt> <dd>An event handler that runs when an event of type <code><a href="https://developer.mozilla.org/en-US/docs/Web/Events/statechange" target="_blank">statechange</a></code> has fired. This occurs when the <code>AudioContext</code>'s state changes, due to the calling of one of the state change methods (<a href="../audiocontext/suspend/"><code>AudioContext.suspend</code></a>, <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/resume" target="_blank"><code>AudioContext.resume</code></a>, or <a href="../audiocontext/close/"><code>AudioContext.close</code></a>).</dd> </dl> <h2 id="Methods">Methods</h2> <p><em>Also implements methods from the interface </em><a href="../eventtarget/"><code>EventTarget</code></a>.</p> <dl> <dt><a href="../baseaudiocontext/createbuffer/"><code>BaseAudioContext.createBuffer()</code></a></dt> <dd>Creates a new, empty <a href="../audiobuffer/"><code>AudioBuffer</code></a> object, which can then be populated by data and played via an <a href="../audiobuffersourcenode/"><code>AudioBufferSourceNode</code></a>.</dd> <dt><a href="../baseaudiocontext/createconstantsource/"><code>BaseAudioContext.createConstantSource()</code></a></dt> <dd>Creates a <a href="../constantsourcenode/"><code>ConstantSourceNode</code></a> object, which is an audio source that continuously outputs a monaural (one-channel) sound signal whose samples all have the same value.</dd> <dt><a href="../baseaudiocontext/createbuffersource/"><code>BaseAudioContext.createBufferSource()</code></a></dt> <dd>Creates an <a href="../audiobuffersourcenode/"><code>AudioBufferSourceNode</code></a>, which can be used to play and manipulate audio data contained within an <a href="../audiobuffer/"><code>AudioBuffer</code></a> object. <a href="../audiobuffer/"><code>AudioBuffer</code></a>s are created using <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createBuffer" target="_blank"><code>AudioContext.createBuffer</code></a> or returned by <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/decodeAudioData" target="_blank"><code>AudioContext.decodeAudioData</code></a> when it successfully decodes an audio track.</dd> <dt><a href="../baseaudiocontext/createscriptprocessor/"><code>BaseAudioContext.createScriptProcessor()</code></a></dt> <dd>Creates a <a href="../scriptprocessornode/"><code>ScriptProcessorNode</code></a>, which can be used for direct audio processing via JavaScript.</dd> <dt><a href="../baseaudiocontext/createstereopanner/"><code>BaseAudioContext.createStereoPanner()</code></a></dt> <dd>Creates a <a href="../stereopannernode/"><code>StereoPannerNode</code></a>, which can be used to apply stereo panning to an audio source.</dd> <dt><a href="../baseaudiocontext/createanalyser/"><code>BaseAudioContext.createAnalyser()</code></a></dt> <dd>Creates an <a href="../analysernode/"><code>AnalyserNode</code></a>, which can be used to expose audio time and frequency data and for example to create data visualisations.</dd> <dt><a href="../baseaudiocontext/createbiquadfilter/"><code>BaseAudioContext.createBiquadFilter()</code></a></dt> <dd>Creates a <a href="../biquadfilternode/"><code>BiquadFilterNode</code></a>, which represents a second order filter configurable as several different common filter types: high-pass, low-pass, band-pass, etc.</dd> <dt><a href="../baseaudiocontext/createchannelmerger/"><code>BaseAudioContext.createChannelMerger()</code></a></dt> <dd>Creates a <a href="../channelmergernode/"><code>ChannelMergerNode</code></a>, which is used to combine channels from multiple audio streams into a single audio stream.</dd> <dt><a href="../baseaudiocontext/createchannelsplitter/"><code>BaseAudioContext.createChannelSplitter()</code></a></dt> <dd>Creates a <a href="../channelsplitternode/"><code>ChannelSplitterNode</code></a>, which is used to access the individual channels of an audio stream and process them separately.</dd> <dt><a href="../baseaudiocontext/createconvolver/"><code>BaseAudioContext.createConvolver()</code></a></dt> <dd>Creates a <a href="../convolvernode/"><code>ConvolverNode</code></a>, which can be used to apply convolution effects to your audio graph, for example a reverberation effect.</dd> <dt><a href="../baseaudiocontext/createdelay/"><code>BaseAudioContext.createDelay()</code></a></dt> <dd>Creates a <a href="../delaynode/"><code>DelayNode</code></a>, which is used to delay the incoming audio signal by a certain amount. This node is also useful to create feedback loops in a Web Audio API graph.</dd> <dt><a href="../baseaudiocontext/createdynamicscompressor/"><code>BaseAudioContext.createDynamicsCompressor()</code></a></dt> <dd>Creates a <a href="../dynamicscompressornode/"><code>DynamicsCompressorNode</code></a>, which can be used to apply acoustic compression to an audio signal.</dd> <dt><a href="../baseaudiocontext/creategain/"><code>BaseAudioContext.createGain()</code></a></dt> <dd>Creates a <a href="../gainnode/"><code>GainNode</code></a>, which can be used to control the overall volume of the audio graph.</dd> <dt><a href="../baseaudiocontext/createiirfilter/"><code>BaseAudioContext.createIIRFilter()</code></a></dt> <dd>Creates an <a href="../iirfilternode/"><code>IIRFilterNode</code></a>, which represents a second order filter configurable as several different common filter types.</dd> <dt><a href="../baseaudiocontext/createoscillator/"><code>BaseAudioContext.createOscillator()</code></a></dt> <dd>Creates an <a href="../oscillatornode/"><code>OscillatorNode</code></a>, a source representing a periodic waveform. It basically generates a tone.</dd> <dt><a href="../baseaudiocontext/createpanner/"><code>BaseAudioContext.createPanner()</code></a></dt> <dd>Creates a <a href="../pannernode/"><code>PannerNode</code></a>, which is used to spatialise an incoming audio stream in 3D space.</dd> <dt><a href="../baseaudiocontext/createperiodicwave/"><code>BaseAudioContext.createPeriodicWave()</code></a></dt> <dd>Creates a <a href="../periodicwave/"><code>PeriodicWave</code></a>, used to define a periodic waveform that can be used to determine the output of an <a href="../oscillatornode/"><code>OscillatorNode</code></a>.</dd> <dt><a href="../baseaudiocontext/createwaveshaper/"><code>BaseAudioContext.createWaveShaper()</code></a></dt> <dd>Creates a <a href="../waveshapernode/"><code>WaveShaperNode</code></a>, which is used to implement non-linear distortion effects.</dd> <dt><a href="../baseaudiocontext/decodeaudiodata/"><code>BaseAudioContext.decodeAudioData()</code></a></dt> <dd>Asynchronously decodes audio file data contained in an <a href="https://developer.mozilla.org/en-US/docs/Web/API/ArrayBuffer" target="_blank"><code>ArrayBuffer</code></a>. In this case, the ArrayBuffer is usually loaded from an <a href="../xmlhttprequest/"><code>XMLHttpRequest</code></a>'s <code>response</code> attribute after setting the <code>responseType</code> to <code>arraybuffer</code>. This method only works on complete files, not fragments of audio files.</dd> <dt><a href="../baseaudiocontext/resume/"><code>BaseAudioContext.resume()</code></a></dt> <dd>Resumes the progression of time in an audio context that has previously been suspended/paused.</dd> </dl> <h2 id="Examples">Examples</h2> <p>Basic audio context declaration:</p> <pre data-language="js">var audioCtx = new AudioContext();</pre> <p>Cross browser variant:</p> <pre data-language="js">var AudioContext = window.AudioContext || window.webkitAudioContext;
var audioCtx = new AudioContext();

var oscillatorNode = audioCtx.createOscillator();
var gainNode = audioCtx.createGain();
var finish = audioCtx.destination;
// etc.</pre> <h2 id="Specifications">Specifications</h2> <div class="_table"><table class="standard-table"> <tbody> <tr> <th scope="col">Specification</th> <th scope="col">Status</th> <th scope="col">Comment</th> </tr> <tr> <td><a href="https://webaudio.github.io/web-audio-api/#BaseAudioContext" hreflang="en" target="_blank">Web Audio API<br><small>The definition of 'BaseAudioContext' in that specification.</small></a></td> <td><span class="spec-WD">Working Draft</span></td> <td> </td> </tr> </tbody> </table></div> <h2 id="Browser_compatibility">Browser compatibility</h2>   <div class="_table"><table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Chrome</th> <th>Edge</th> <th>Firefox (Gecko)</th> <th>Internet Explorer</th> <th>Opera</th> <th>Safari (WebKit)</th> </tr> <tr> <td>Basic support</td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #f00;">No support</span></td> <td>15.0<span class="inlineIndicator prefixBox prefixBoxInline"><a href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes" target="_blank">webkit</a></span><br> 22</td> <td>6.0<span class="inlineIndicator prefixBox prefixBoxInline"><a href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes" target="_blank">webkit</a></span>
</td> </tr> <tr> <td><code>baseLatency</code></td> <td>60</td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> </tr> <tr> <td><code>createConstantSource()</code></td> <td>56</td> <td><span style="color: #f00;">No support</span></td> <td>
<a href="https://developer.mozilla.org/en-US/Firefox/Releases/52" target="_blank">52</a> (52)</td> <td><span style="color: #f00;">No support</span></td> <td>43</td> <td><span style="color: #f00;">No support</span></td> </tr> <tr> <td><code>createStereoPanner()</code></td> <td>42</td> <td><span style="color: #888;">(Yes)</span></td> <td>
<a href="https://developer.mozilla.org/en-US/Firefox/Releases/37" target="_blank">37.0</a> (37.0) </td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> </tr> <tr> <td>
<code>onstatechange</code>, <code>state</code>, <code>suspend()</code>, <code>resume()</code>
</td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td>
<a href="https://developer.mozilla.org/en-US/Firefox/Releases/40" target="_blank">40.0</a> (40.0)</td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td>8.0</td> </tr> <tr> <td>Unprefixed</td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td> </td> <td> </td> <td> </td> <td> </td> </tr> </tbody> </table></div>   <div class="_table"><table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Android Webview</th> <th>Chrome for Android</th> <th>Edge</th> <th>Firefox Mobile (Gecko)</th> <th>Firefox OS</th> <th>IE Mobile</th> <th>Opera Mobile</th> <th>Safari Mobile</th> </tr> <tr> <td>Basic support</td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td>2.2</td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #f00;">No support</span></td> </tr> <tr> <td><code>baseLatency</code></td> <td>60</td> <td>60</td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> </tr> <tr> <td><code>createConstantSource()</code></td> <td>56</td> <td>56</td> <td><span style="color: #f00;">No support</span></td> <td>52.0 (52)</td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> </tr> <tr> <td><code>createStereoPanner()</code></td> <td>42</td> <td>42</td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> </tr> <tr> <td>
<code>onstatechange</code>, <code>state</code>, <code>suspend()</code>, <code>resume()</code>
</td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> </tr> <tr> <td>Unprefixed</td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: #888;">(Yes)</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: rgb(255, 153, 0);">?</span></td> <td>43</td> <td><span style="color: rgb(255, 153, 0);">?</span></td> </tr> </tbody> </table></div>  <h2 id="See_also">See also</h2> <ul style="margin-left: 40px;"> <li><a href="https://developer.mozilla.org/en-US/docs/Web_Audio_API/Using_Web_Audio_API" target="_blank">Using the Web Audio API</a></li> <li><a href="../audiocontext/"><code>AudioContext</code></a></li> <li><a href="../offlineaudiocontext/"><code>OfflineAudioContext</code></a></li> </ul>
<div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext%24edit" class="_attribution-link" target="_blank">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    Â© 2005â€“2018 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext" class="_attribution-link" target="_blank">https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
	<svg style="display:none">
		<symbol id="icon-dir"><svg viewBox="0 0 20 20"><path d="M15 10c0 .3-.305.515-.305.515l-8.56 5.303c-.625.41-1.135.106-1.135-.67V4.853c0-.777.51-1.078 1.135-.67l8.56 5.305S15 9.702 15 10z"/></svg></symbol>
	  </svg>
</body>
</html>
